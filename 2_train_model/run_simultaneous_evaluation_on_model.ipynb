{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train an object detection model using Tensorflow on SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker.estimator import Framework, Estimator\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "inputs = {'train': 's3://sagemaker-gauge-detection-training-070122/data/'} # define s3 training data inputs, this is the output of the processing job\n",
    "tensorboard_s3_prefix = 's3://sagemaker-gauge-detection-training-070122/output/' # s3 path for tensorboard events, up to you where to save events "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = 'tf2-object-detection'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720148074160.dkr.ecr.us-east-1.amazonaws.com/tf2-object-detection:20220707201336\n"
     ]
    }
   ],
   "source": [
    "with open (os.path.join('docker', 'ecr_image_fullname.txt'), 'r') as f:\n",
    "    container = f.readlines()[0][:-1]\n",
    "\n",
    "print(container)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SageMaker Custom Framework and Launch Training job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define a custom framework estimator using the Amazon SageMaker Python SDK and run training with that class, which will take care of managing these tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class CustomFramework(Framework):\n",
    "    def __init__(\n",
    "        self,\n",
    "        entry_point,\n",
    "        framework_version=None,\n",
    "        py_version=None,\n",
    "        source_dir=None,\n",
    "        hyperparameters=None,\n",
    "        image_uri=None,\n",
    "        distribution=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super(CustomFramework, self).__init__(\n",
    "            entry_point, source_dir, hyperparameters, image_uri=image_uri, **kwargs\n",
    "        )\n",
    "        self.framework_version = framework_version\n",
    "        self.py_version = None\n",
    "        \n",
    "    def _configure_distribution(self, distributions):\n",
    "        return None\n",
    "\n",
    "    def create_model(\n",
    "        self,\n",
    "        model_server_workers=None,\n",
    "        role=None,\n",
    "        vpc_config_override=None,\n",
    "        entry_point=None,\n",
    "        source_dir=None,\n",
    "        dependencies=None,\n",
    "        image_uri=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tensorboard_output_config = sagemaker.debugger.TensorBoardOutputConfig(\n",
    "    s3_output_path=tensorboard_s3_prefix,\n",
    "    container_local_output_path='/opt/training/'\n",
    ")\n",
    "\n",
    "estimator = CustomFramework(\n",
    "    role=role,\n",
    "    image_uri=container,\n",
    "    entry_point='run_simultaneous_evaluation.sh',\n",
    "    source_dir='source_dir/',\n",
    "    hyperparameters={\n",
    "        \"model_dir\":\"s3://sagemaker-gauge-detection-training-070122/test_train_eval/model-base-070722/\",        \n",
    "        \"pipeline_config_path\": \"pipeline.config\",\n",
    "        \"num_train_steps\": \"40000\",    \n",
    "        \"sample_1_of_n_eval_examples\": \"1\"\n",
    "    },\n",
    "    instance_count=1,\n",
    "    instance_type='ml.g4dn.2xlarge',\n",
    "    tensorboard_output_config=tensorboard_output_config,\n",
    "    disable_profiler=True,\n",
    "    base_job_name='tf2-object-detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-07 20:32:46 Starting - Starting the training job...\n",
      "2022-07-07 20:33:11 Starting - Preparing the instances for training.........\n",
      "2022-07-07 20:34:28 Downloading - Downloading input data.........\n",
      "2022-07-07 20:36:08 Training - Downloading the training image...\n",
      "2022-07-07 20:36:39 Training - Training image download completed. Training in progress..\u001b[34m2022-07-07 20:36:42,303 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": null,\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"model_dir\": \"s3://sagemaker-gauge-detection-training-070122/test_train_eval/model-base-070722/\",\n",
      "        \"num_train_steps\": \"40000\",\n",
      "        \"pipeline_config_path\": \"pipeline.config\",\n",
      "        \"sample_1_of_n_eval_examples\": \"1\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"job_name\": \"tf2-object-detection-2022-07-07-20-32-44-502\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-720148074160/tf2-object-detection-2022-07-07-20-32-44-502/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"run_simultaneous_evaluation.sh\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g4dn.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g4dn.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"run_simultaneous_evaluation.sh\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"model_dir\":\"s3://sagemaker-gauge-detection-training-070122/test_train_eval/model-base-070722/\",\"num_train_steps\":\"40000\",\"pipeline_config_path\":\"pipeline.config\",\"sample_1_of_n_eval_examples\":\"1\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=run_simultaneous_evaluation.sh\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=run_simultaneous_evaluation.sh\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-720148074160/tf2-object-detection-2022-07-07-20-32-44-502/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":null,\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"model_dir\":\"s3://sagemaker-gauge-detection-training-070122/test_train_eval/model-base-070722/\",\"num_train_steps\":\"40000\",\"pipeline_config_path\":\"pipeline.config\",\"sample_1_of_n_eval_examples\":\"1\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"is_modelparallel_enabled\":null,\"job_name\":\"tf2-object-detection-2022-07-07-20-32-44-502\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-720148074160/tf2-object-detection-2022-07-07-20-32-44-502/source/sourcedir.tar.gz\",\"module_name\":\"run_simultaneous_evaluation.sh\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"run_simultaneous_evaluation.sh\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--model_dir\",\"s3://sagemaker-gauge-detection-training-070122/test_train_eval/model-base-070722/\",\"--num_train_steps\",\"40000\",\"--pipeline_config_path\",\"pipeline.config\",\"--sample_1_of_n_eval_examples\",\"1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=s3://sagemaker-gauge-detection-training-070122/test_train_eval/model-base-070722/\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_TRAIN_STEPS=40000\u001b[0m\n",
      "\u001b[34mSM_HP_PIPELINE_CONFIG_PATH=pipeline.config\u001b[0m\n",
      "\u001b[34mSM_HP_SAMPLE_1_OF_N_EVAL_EXAMPLES=1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python38.zip:/usr/lib/python3.8:/usr/lib/python3.8/lib-dynload:/usr/local/lib/python3.8/dist-packages:/usr/lib/python3/dist-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/bin/sh -c \"./run_simultaneous_evaluation.sh --model_dir s3://sagemaker-gauge-detection-training-070122/test_train_eval/model-base-070722/ --num_train_steps 40000 --pipeline_config_path pipeline.config --sample_1_of_n_eval_examples 1\"\u001b[0m\n",
      "\u001b[34m===TRAINING THE MODEL==\u001b[0m\n",
      "\u001b[34m==EVALUATING THE MODEL==\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\u001b[0m\n",
      "\u001b[34mW0707 20:36:50.339952 140454606952256 model_lib_v2.py:1089] Forced number of epochs for all eval validations to be 1.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\u001b[0m\n",
      "\u001b[34mI0707 20:36:50.340247 140454606952256 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Maybe overwriting use_bfloat16: False\u001b[0m\n",
      "\u001b[34mI0707 20:36:50.340374 140454606952256 config_util.py:552] Maybe overwriting use_bfloat16: False\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Maybe overwriting eval_num_epochs: 1\u001b[0m\n",
      "\u001b[34mI0707 20:36:50.340470 140454606952256 config_util.py:552] Maybe overwriting eval_num_epochs: 1\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\u001b[0m\n",
      "\u001b[34mW0707 20:36:50.340595 140454606952256 model_lib_v2.py:1106] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\u001b[0m\n",
      "\u001b[34mI0707 20:36:52.464808 140454606952256 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b1\u001b[0m\n",
      "\u001b[34mI0707 20:36:52.464979 140454606952256 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 88\u001b[0m\n",
      "\u001b[34mI0707 20:36:52.465041 140454606952256 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 4\u001b[0m\n",
      "\u001b[34mI0707 20:36:52.469202 140454606952256 efficientnet_model.py:143] round_filter input=32 output=32\u001b[0m\n",
      "\u001b[34mI0707 20:36:52.504819 140454606952256 efficientnet_model.py:143] round_filter input=32 output=32\u001b[0m\n",
      "\u001b[34mI0707 20:36:52.504951 140454606952256 efficientnet_model.py:143] round_filter input=16 output=16\u001b[0m\n",
      "\u001b[34mI0707 20:36:52.622893 140454606952256 efficientnet_model.py:143] round_filter input=16 output=16\u001b[0m\n",
      "\u001b[34mI0707 20:36:52.623032 140454606952256 efficientnet_model.py:143] round_filter input=24 output=24\u001b[0m\n",
      "\u001b[34mI0707 20:36:52.833022 140454606952256 efficientnet_model.py:143] round_filter input=24 output=24\u001b[0m\n",
      "\u001b[34mI0707 20:36:52.833163 140454606952256 efficientnet_model.py:143] round_filter input=40 output=40\u001b[0m\n",
      "\u001b[34mI0707 20:36:53.041537 140454606952256 efficientnet_model.py:143] round_filter input=40 output=40\u001b[0m\n",
      "\u001b[34mI0707 20:36:53.041672 140454606952256 efficientnet_model.py:143] round_filter input=80 output=80\u001b[0m\n",
      "\u001b[34mI0707 20:36:53.320848 140454606952256 efficientnet_model.py:143] round_filter input=80 output=80\u001b[0m\n",
      "\u001b[34mI0707 20:36:53.320992 140454606952256 efficientnet_model.py:143] round_filter input=112 output=112\u001b[0m\n",
      "\u001b[34mI0707 20:36:53.598243 140454606952256 efficientnet_model.py:143] round_filter input=112 output=112\u001b[0m\n",
      "\u001b[34mI0707 20:36:53.598399 140454606952256 efficientnet_model.py:143] round_filter input=192 output=192\u001b[0m\n",
      "\u001b[34mI0707 20:36:53.940154 140454606952256 efficientnet_model.py:143] round_filter input=192 output=192\u001b[0m\n",
      "\u001b[34mI0707 20:36:53.940295 140454606952256 efficientnet_model.py:143] round_filter input=320 output=320\u001b[0m\n",
      "\u001b[34mI0707 20:36:54.075307 140454606952256 efficientnet_model.py:143] round_filter input=1280 output=1280\u001b[0m\n",
      "\u001b[34mI0707 20:36:54.104627 140454606952256 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reading unweighted datasets: ['s3://sagemaker-gauge-detection-training-070122/data/gauge-synthetic-val/coco_val.record*']\u001b[0m\n",
      "\u001b[34mI0707 20:36:54.642950 140454606952256 dataset_builder.py:162] Reading unweighted datasets: ['s3://sagemaker-gauge-detection-training-070122/data/gauge-synthetic-val/coco_val.record*']\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reading record datasets for input file: ['s3://sagemaker-gauge-detection-training-070122/data/gauge-synthetic-val/coco_val.record*']\u001b[0m\n",
      "\u001b[34mI0707 20:36:55.207385 140454606952256 dataset_builder.py:79] Reading record datasets for input file: ['s3://sagemaker-gauge-detection-training-070122/data/gauge-synthetic-val/coco_val.record*']\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Number of filenames to read: 50\u001b[0m\n",
      "\u001b[34mI0707 20:36:55.207613 140454606952256 dataset_builder.py:80] Number of filenames to read: 50\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:num_readers has been reduced to 50 to match input file shards.\u001b[0m\n",
      "\u001b[34mW0707 20:36:55.207706 140454606952256 dataset_builder.py:86] num_readers has been reduced to 50 to match input file shards.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:`shuffle` is false, but the input data stream is still slightly shuffled since `num_readers` > 1.\u001b[0m\n",
      "\u001b[34mW0707 20:36:55.211464 140454606952256 dataset_builder.py:93] `shuffle` is false, but the input data stream is still slightly shuffled since `num_readers` > 1.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\u001b[0m\n",
      "\u001b[34mW0707 20:36:55.213224 140454606952256 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.map()\u001b[0m\n",
      "\u001b[34mW0707 20:36:55.244266 140454606952256 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.map()\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\u001b[0m\n",
      "\u001b[34mW0707 20:36:58.688874 140454606952256 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34mW0707 20:36:59.910322 140454606952256 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Waiting for new checkpoint at s3://sagemaker-gauge-detection-training-070122/test_train_eval/model-base-070722/\u001b[0m\n",
      "\u001b[34mI0707 20:37:02.409176 140454606952256 checkpoint_utils.py:136] Waiting for new checkpoint at s3://sagemaker-gauge-detection-training-070122/test_train_eval/model-base-070722/\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Found new checkpoint at s3://sagemaker-gauge-detection-training-070122/test_train_eval/model-base-070722/ckpt-1\u001b[0m\n",
      "\u001b[34mI0707 20:39:02.199847 140454606952256 checkpoint_utils.py:145] Found new checkpoint at s3://sagemaker-gauge-detection-training-070122/test_train_eval/model-base-070722/ckpt-1\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.8/dist-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34mW0707 20:41:46.449187 140454606952256 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 0\u001b[0m\n",
      "\u001b[34mI0707 20:41:46.457352 140454606952256 model_lib_v2.py:966] Finished eval step 0\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mtf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \u001b[0m\n",
      "\u001b[34mW0707 20:41:46.579069 140454606952256 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mtf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 100\u001b[0m\n",
      "\u001b[34mI0707 20:41:58.747550 140454606952256 model_lib_v2.py:966] Finished eval step 100\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 200\u001b[0m\n",
      "\u001b[34mI0707 20:42:05.242703 140454606952256 model_lib_v2.py:966] Finished eval step 200\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 300\u001b[0m\n",
      "\u001b[34mI0707 20:42:11.596176 140454606952256 model_lib_v2.py:966] Finished eval step 300\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 400\u001b[0m\n",
      "\u001b[34mI0707 20:42:18.012383 140454606952256 model_lib_v2.py:966] Finished eval step 400\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 500\u001b[0m\n",
      "\u001b[34mI0707 20:42:24.419760 140454606952256 model_lib_v2.py:966] Finished eval step 500\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 600\u001b[0m\n",
      "\u001b[34mI0707 20:42:30.872654 140454606952256 model_lib_v2.py:966] Finished eval step 600\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 700\u001b[0m\n",
      "\u001b[34mI0707 20:42:37.297890 140454606952256 model_lib_v2.py:966] Finished eval step 700\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 800\u001b[0m\n",
      "\u001b[34mI0707 20:42:43.696929 140454606952256 model_lib_v2.py:966] Finished eval step 800\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 900\u001b[0m\n",
      "\u001b[34mI0707 20:42:50.156195 140454606952256 model_lib_v2.py:966] Finished eval step 900\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 1000\u001b[0m\n",
      "\u001b[34mI0707 20:42:56.612082 140454606952256 model_lib_v2.py:966] Finished eval step 1000\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 1100\u001b[0m\n",
      "\u001b[34mI0707 20:43:03.004515 140454606952256 model_lib_v2.py:966] Finished eval step 1100\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 1200\u001b[0m\n",
      "\u001b[34mI0707 20:43:09.482300 140454606952256 model_lib_v2.py:966] Finished eval step 1200\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Performing evaluation on 1213 images.\u001b[0m\n",
      "\u001b[34mI0707 20:43:10.229197 140454606952256 coco_evaluation.py:293] Performing evaluation on 1213 images.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Loading and preparing annotation results...\u001b[0m\n",
      "\u001b[34mI0707 20:43:10.234261 140454606952256 coco_tools.py:116] Loading and preparing annotation results...\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:DONE (t=0.00s)\u001b[0m\n",
      "\u001b[34mI0707 20:43:10.234550 140454606952256 coco_tools.py:138] DONE (t=0.00s)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Eval metrics at step 0\u001b[0m\n",
      "\u001b[34mI0707 20:43:10.727310 140454606952256 model_lib_v2.py:1015] Eval metrics at step 0\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP: 0.000000\u001b[0m\n",
      "\u001b[34mI0707 20:43:10.729370 140454606952256 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP: 0.000000\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP@.50IOU: 0.000000\u001b[0m\n",
      "\u001b[34mI0707 20:43:10.952690 140454606952256 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP@.50IOU: 0.000000\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP@.75IOU: 0.000000\u001b[0m\n",
      "\u001b[34mI0707 20:43:10.954475 140454606952256 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP@.75IOU: 0.000000\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP (small): -1.000000\u001b[0m\n",
      "\u001b[34mI0707 20:43:10.955842 140454606952256 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP (small): -1.000000\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP (medium): 0.000000\u001b[0m\n",
      "\u001b[34mI0707 20:43:10.956635 140454606952256 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP (medium): 0.000000\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP (large): 0.000000\u001b[0m\n",
      "\u001b[34mI0707 20:43:10.957430 140454606952256 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP (large): 0.000000\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@1: 0.000000\u001b[0m\n",
      "\u001b[34mI0707 20:43:10.958214 140454606952256 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@1: 0.000000\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@10: 0.000000\u001b[0m\n",
      "\u001b[34mI0707 20:43:10.959040 140454606952256 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@10: 0.000000\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@100: 0.000000\u001b[0m\n",
      "\u001b[34mI0707 20:43:10.959829 140454606952256 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@100: 0.000000\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@100 (small): -1.000000\u001b[0m\n",
      "\u001b[34mI0707 20:43:10.960612 140454606952256 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@100 (small): -1.000000\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@100 (medium): 0.000000\u001b[0m\n",
      "\u001b[34mI0707 20:43:10.961390 140454606952256 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@100 (medium): 0.000000\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@100 (large): 0.000000\u001b[0m\n",
      "\u001b[34mI0707 20:43:10.962184 140454606952256 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@100 (large): 0.000000\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ Loss/localization_loss: 0.024006\u001b[0m\n",
      "\u001b[34mI0707 20:43:11.085792 140454606952256 model_lib_v2.py:1018] #011+ Loss/localization_loss: 0.024006\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ Loss/classification_loss: 1.146100\u001b[0m\n",
      "\u001b[34mI0707 20:43:11.087287 140454606952256 model_lib_v2.py:1018] #011+ Loss/classification_loss: 1.146100\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ Loss/regularization_loss: 0.029538\u001b[0m\n",
      "\u001b[34mI0707 20:43:11.088203 140454606952256 model_lib_v2.py:1018] #011+ Loss/regularization_loss: 0.029538\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ Loss/total_loss: 1.199644\u001b[0m\n",
      "\u001b[34mI0707 20:43:11.089042 140454606952256 model_lib_v2.py:1018] #011+ Loss/total_loss: 1.199644\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Waiting for new checkpoint at s3://sagemaker-gauge-detection-training-070122/test_train_eval/model-base-070722/\u001b[0m\n",
      "\u001b[34mI0707 20:44:02.250442 140454606952256 checkpoint_utils.py:136] Waiting for new checkpoint at s3://sagemaker-gauge-detection-training-070122/test_train_eval/model-base-070722/\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Found new checkpoint at s3://sagemaker-gauge-detection-training-070122/test_train_eval/model-base-070722/ckpt-2\u001b[0m\n",
      "\u001b[34mI0707 20:44:02.530007 140454606952256 checkpoint_utils.py:145] Found new checkpoint at s3://sagemaker-gauge-detection-training-070122/test_train_eval/model-base-070722/ckpt-2\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 0\u001b[0m\n",
      "\u001b[34mI0707 20:46:57.398242 140454606952256 model_lib_v2.py:966] Finished eval step 0\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 100\u001b[0m\n",
      "\u001b[34mI0707 20:47:09.903732 140454606952256 model_lib_v2.py:966] Finished eval step 100\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 200\u001b[0m\n",
      "\u001b[34mI0707 20:47:16.881308 140454606952256 model_lib_v2.py:966] Finished eval step 200\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 300\u001b[0m\n",
      "\u001b[34mI0707 20:47:23.610184 140454606952256 model_lib_v2.py:966] Finished eval step 300\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 400\u001b[0m\n",
      "\u001b[34mI0707 20:47:30.319973 140454606952256 model_lib_v2.py:966] Finished eval step 400\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 500\u001b[0m\n",
      "\u001b[34mI0707 20:47:37.116148 140454606952256 model_lib_v2.py:966] Finished eval step 500\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 600\u001b[0m\n",
      "\u001b[34mI0707 20:47:43.839842 140454606952256 model_lib_v2.py:966] Finished eval step 600\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 700\u001b[0m\n",
      "\u001b[34mI0707 20:47:50.561163 140454606952256 model_lib_v2.py:966] Finished eval step 700\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 800\u001b[0m\n",
      "\u001b[34mI0707 20:47:57.296196 140454606952256 model_lib_v2.py:966] Finished eval step 800\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 900\u001b[0m\n",
      "\u001b[34mI0707 20:48:04.310803 140454606952256 model_lib_v2.py:966] Finished eval step 900\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 1000\u001b[0m\n",
      "\u001b[34mI0707 20:48:11.073845 140454606952256 model_lib_v2.py:966] Finished eval step 1000\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 1100\u001b[0m\n",
      "\u001b[34mI0707 20:48:17.841015 140454606952256 model_lib_v2.py:966] Finished eval step 1100\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 1200\u001b[0m\n",
      "\u001b[34mI0707 20:48:24.653030 140454606952256 model_lib_v2.py:966] Finished eval step 1200\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Performing evaluation on 1213 images.\u001b[0m\n",
      "\u001b[34mI0707 20:48:25.423741 140454606952256 coco_evaluation.py:293] Performing evaluation on 1213 images.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Loading and preparing annotation results...\u001b[0m\n",
      "\u001b[34mI0707 20:48:25.427759 140454606952256 coco_tools.py:116] Loading and preparing annotation results...\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:DONE (t=0.07s)\u001b[0m\n",
      "\u001b[34mI0707 20:48:25.499742 140454606952256 coco_tools.py:138] DONE (t=0.07s)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Eval metrics at step 100\u001b[0m\n",
      "\u001b[34mI0707 20:48:33.478034 140454606952256 model_lib_v2.py:1015] Eval metrics at step 100\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP: 0.178635\u001b[0m\n",
      "\u001b[34mI0707 20:48:33.645076 140454606952256 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP: 0.178635\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP@.50IOU: 0.598960\u001b[0m\n",
      "\u001b[34mI0707 20:48:33.646671 140454606952256 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP@.50IOU: 0.598960\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP@.75IOU: 0.030311\u001b[0m\n",
      "\u001b[34mI0707 20:48:33.647698 140454606952256 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP@.75IOU: 0.030311\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP (small): -1.000000\u001b[0m\n",
      "\u001b[34mI0707 20:48:33.648549 140454606952256 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP (small): -1.000000\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP (medium): 0.396177\u001b[0m\n",
      "\u001b[34mI0707 20:48:33.649440 140454606952256 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP (medium): 0.396177\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP (large): 0.178484\u001b[0m\n",
      "\u001b[34mI0707 20:48:33.650343 140454606952256 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP (large): 0.178484\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@1: 0.127090\u001b[0m\n",
      "\u001b[34mI0707 20:48:33.651302 140454606952256 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@1: 0.127090\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@10: 0.341724\u001b[0m\n",
      "\u001b[34mI0707 20:48:33.652211 140454606952256 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@10: 0.341724\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@100: 0.356229\u001b[0m\n",
      "\u001b[34mI0707 20:48:33.653103 140454606952256 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@100: 0.356229\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@100 (small): -1.000000\u001b[0m\n",
      "\u001b[34mI0707 20:48:33.653940 140454606952256 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@100 (small): -1.000000\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@100 (medium): 0.400000\u001b[0m\n",
      "\u001b[34mI0707 20:48:33.654922 140454606952256 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@100 (medium): 0.400000\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@100 (large): 0.352914\u001b[0m\n",
      "\u001b[34mI0707 20:48:33.808249 140454606952256 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@100 (large): 0.352914\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ Loss/localization_loss: 0.023217\u001b[0m\n",
      "\u001b[34mI0707 20:48:33.809698 140454606952256 model_lib_v2.py:1018] #011+ Loss/localization_loss: 0.023217\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ Loss/classification_loss: 1.136829\u001b[0m\n",
      "\u001b[34mI0707 20:48:33.810732 140454606952256 model_lib_v2.py:1018] #011+ Loss/classification_loss: 1.136829\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ Loss/regularization_loss: 0.029543\u001b[0m\n",
      "\u001b[34mI0707 20:48:33.811500 140454606952256 model_lib_v2.py:1018] #011+ Loss/regularization_loss: 0.029543\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ Loss/total_loss: 1.189590\u001b[0m\n",
      "\u001b[34mI0707 20:48:33.812375 140454606952256 model_lib_v2.py:1018] #011+ Loss/total_loss: 1.189590\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Waiting for new checkpoint at s3://sagemaker-gauge-detection-training-070122/test_train_eval/model-base-070722/\u001b[0m\n",
      "\u001b[34mI0707 20:49:02.558443 140454606952256 checkpoint_utils.py:136] Waiting for new checkpoint at s3://sagemaker-gauge-detection-training-070122/test_train_eval/model-base-070722/\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Found new checkpoint at s3://sagemaker-gauge-detection-training-070122/test_train_eval/model-base-070722/ckpt-5\u001b[0m\n",
      "\u001b[34mI0707 20:49:02.760224 140454606952256 checkpoint_utils.py:145] Found new checkpoint at s3://sagemaker-gauge-detection-training-070122/test_train_eval/model-base-070722/ckpt-5\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 0\u001b[0m\n",
      "\u001b[34mI0707 20:49:24.102442 140454606952256 model_lib_v2.py:966] Finished eval step 0\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 100\u001b[0m\n",
      "\u001b[34mI0707 20:49:36.357648 140454606952256 model_lib_v2.py:966] Finished eval step 100\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 200\u001b[0m\n",
      "\u001b[34mI0707 20:49:42.908526 140454606952256 model_lib_v2.py:966] Finished eval step 200\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 300\u001b[0m\n",
      "\u001b[34mI0707 20:49:49.475465 140454606952256 model_lib_v2.py:966] Finished eval step 300\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 400\u001b[0m\n",
      "\u001b[34mI0707 20:49:55.994068 140454606952256 model_lib_v2.py:966] Finished eval step 400\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 500\u001b[0m\n",
      "\u001b[34mI0707 20:50:02.561720 140454606952256 model_lib_v2.py:966] Finished eval step 500\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 600\u001b[0m\n",
      "\u001b[34mI0707 20:50:09.515399 140454606952256 model_lib_v2.py:966] Finished eval step 600\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 700\u001b[0m\n",
      "\u001b[34mI0707 20:50:16.023442 140454606952256 model_lib_v2.py:966] Finished eval step 700\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 800\u001b[0m\n",
      "\u001b[34mI0707 20:50:22.516223 140454606952256 model_lib_v2.py:966] Finished eval step 800\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 900\u001b[0m\n",
      "\u001b[34mI0707 20:50:29.022370 140454606952256 model_lib_v2.py:966] Finished eval step 900\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 1000\u001b[0m\n",
      "\u001b[34mI0707 20:50:35.591627 140454606952256 model_lib_v2.py:966] Finished eval step 1000\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 1100\u001b[0m\n",
      "\u001b[34mI0707 20:50:42.135829 140454606952256 model_lib_v2.py:966] Finished eval step 1100\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 1200\u001b[0m\n",
      "\u001b[34mI0707 20:50:48.717626 140454606952256 model_lib_v2.py:966] Finished eval step 1200\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Performing evaluation on 1213 images.\u001b[0m\n",
      "\u001b[34mI0707 20:50:49.471192 140454606952256 coco_evaluation.py:293] Performing evaluation on 1213 images.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Loading and preparing annotation results...\u001b[0m\n",
      "\u001b[34mI0707 20:50:49.477235 140454606952256 coco_tools.py:116] Loading and preparing annotation results...\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:DONE (t=0.08s)\u001b[0m\n",
      "\u001b[34mI0707 20:50:49.558522 140454606952256 coco_tools.py:138] DONE (t=0.08s)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Eval metrics at step 400\u001b[0m\n",
      "\u001b[34mI0707 20:50:57.634704 140454606952256 model_lib_v2.py:1015] Eval metrics at step 400\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP: 0.461730\u001b[0m\n",
      "\u001b[34mI0707 20:50:57.823432 140454606952256 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP: 0.461730\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP@.50IOU: 0.988333\u001b[0m\n",
      "\u001b[34mI0707 20:50:57.824902 140454606952256 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP@.50IOU: 0.988333\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP@.75IOU: 0.306131\u001b[0m\n",
      "\u001b[34mI0707 20:50:57.826296 140454606952256 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP@.75IOU: 0.306131\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP (small): -1.000000\u001b[0m\n",
      "\u001b[34mI0707 20:50:57.827182 140454606952256 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP (small): -1.000000\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP (medium): 0.518401\u001b[0m\n",
      "\u001b[34mI0707 20:50:57.828094 140454606952256 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP (medium): 0.518401\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP (large): 0.460132\u001b[0m\n",
      "\u001b[34mI0707 20:50:57.828989 140454606952256 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP (large): 0.460132\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@1: 0.281143\u001b[0m\n",
      "\u001b[34mI0707 20:50:57.829893 140454606952256 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@1: 0.281143\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@10: 0.510623\u001b[0m\n",
      "\u001b[34mI0707 20:50:57.830824 140454606952256 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@10: 0.510623\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@100: 0.511177\u001b[0m\n",
      "\u001b[34mI0707 20:50:57.831707 140454606952256 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@100: 0.511177\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@100 (small): -1.000000\u001b[0m\n",
      "\u001b[34mI0707 20:50:57.832511 140454606952256 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@100 (small): -1.000000\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@100 (medium): 0.529091\u001b[0m\n",
      "\u001b[34mI0707 20:50:57.833442 140454606952256 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@100 (medium): 0.529091\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@100 (large): 0.509821\u001b[0m\n",
      "\u001b[34mI0707 20:50:57.967237 140454606952256 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@100 (large): 0.509821\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ Loss/localization_loss: 0.021894\u001b[0m\n",
      "\u001b[34mI0707 20:50:57.968923 140454606952256 model_lib_v2.py:1018] #011+ Loss/localization_loss: 0.021894\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ Loss/classification_loss: 0.729078\u001b[0m\n",
      "\u001b[34mI0707 20:50:57.969804 140454606952256 model_lib_v2.py:1018] #011+ Loss/classification_loss: 0.729078\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ Loss/regularization_loss: 0.029568\u001b[0m\n",
      "\u001b[34mI0707 20:50:57.970630 140454606952256 model_lib_v2.py:1018] #011+ Loss/regularization_loss: 0.029568\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ Loss/total_loss: 0.780539\u001b[0m\n",
      "\u001b[34mI0707 20:50:57.971373 140454606952256 model_lib_v2.py:1018] #011+ Loss/total_loss: 0.780539\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Waiting for new checkpoint at s3://sagemaker-gauge-detection-training-070122/test_train_eval/model-base-070722/\u001b[0m\n",
      "\u001b[34mI0707 20:54:02.858438 140454606952256 checkpoint_utils.py:136] Waiting for new checkpoint at s3://sagemaker-gauge-detection-training-070122/test_train_eval/model-base-070722/\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Found new checkpoint at s3://sagemaker-gauge-detection-training-070122/test_train_eval/model-base-070722/ckpt-9\u001b[0m\n",
      "\u001b[34mI0707 20:54:03.035978 140454606952256 checkpoint_utils.py:145] Found new checkpoint at s3://sagemaker-gauge-detection-training-070122/test_train_eval/model-base-070722/ckpt-9\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 0\u001b[0m\n",
      "\u001b[34mI0707 20:54:20.351585 140454606952256 model_lib_v2.py:966] Finished eval step 0\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 100\u001b[0m\n",
      "\u001b[34mI0707 20:54:32.351990 140454606952256 model_lib_v2.py:966] Finished eval step 100\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 200\u001b[0m\n",
      "\u001b[34mI0707 20:54:38.558923 140454606952256 model_lib_v2.py:966] Finished eval step 200\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 300\u001b[0m\n",
      "\u001b[34mI0707 20:54:44.768342 140454606952256 model_lib_v2.py:966] Finished eval step 300\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 400\u001b[0m\n",
      "\u001b[34mI0707 20:54:50.944779 140454606952256 model_lib_v2.py:966] Finished eval step 400\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 500\u001b[0m\n",
      "\u001b[34mI0707 20:54:57.167976 140454606952256 model_lib_v2.py:966] Finished eval step 500\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 600\u001b[0m\n",
      "\u001b[34mI0707 20:55:03.639015 140454606952256 model_lib_v2.py:966] Finished eval step 600\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 700\u001b[0m\n",
      "\u001b[34mI0707 20:55:09.886367 140454606952256 model_lib_v2.py:966] Finished eval step 700\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 800\u001b[0m\n",
      "\u001b[34mI0707 20:55:16.073055 140454606952256 model_lib_v2.py:966] Finished eval step 800\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 900\u001b[0m\n",
      "\u001b[34mI0707 20:55:22.286866 140454606952256 model_lib_v2.py:966] Finished eval step 900\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 1000\u001b[0m\n",
      "\u001b[34mI0707 20:55:28.438764 140454606952256 model_lib_v2.py:966] Finished eval step 1000\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 1100\u001b[0m\n",
      "\u001b[34mI0707 20:55:34.608432 140454606952256 model_lib_v2.py:966] Finished eval step 1100\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 1200\u001b[0m\n",
      "\u001b[34mI0707 20:55:40.771433 140454606952256 model_lib_v2.py:966] Finished eval step 1200\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Performing evaluation on 1213 images.\u001b[0m\n",
      "\u001b[34mI0707 20:55:41.494463 140454606952256 coco_evaluation.py:293] Performing evaluation on 1213 images.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Loading and preparing annotation results...\u001b[0m\n",
      "\u001b[34mI0707 20:55:41.498047 140454606952256 coco_tools.py:116] Loading and preparing annotation results...\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:DONE (t=0.07s)\u001b[0m\n",
      "\u001b[34mI0707 20:55:41.565015 140454606952256 coco_tools.py:138] DONE (t=0.07s)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Eval metrics at step 800\u001b[0m\n",
      "\u001b[34mI0707 20:55:49.339872 140454606952256 model_lib_v2.py:1015] Eval metrics at step 800\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP: 0.653617\u001b[0m\n",
      "\u001b[34mI0707 20:55:49.520727 140454606952256 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP: 0.653617\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP@.50IOU: 0.988723\u001b[0m\n",
      "\u001b[34mI0707 20:55:49.522189 140454606952256 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP@.50IOU: 0.988723\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP@.75IOU: 0.850525\u001b[0m\n",
      "\u001b[34mI0707 20:55:49.523201 140454606952256 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP@.75IOU: 0.850525\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP (small): -1.000000\u001b[0m\n",
      "\u001b[34mI0707 20:55:49.524054 140454606952256 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP (small): -1.000000\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP (medium): 0.632935\u001b[0m\n",
      "\u001b[34mI0707 20:55:49.524961 140454606952256 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP (medium): 0.632935\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP (large): 0.657604\u001b[0m\n",
      "\u001b[34mI0707 20:55:49.525869 140454606952256 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP (large): 0.657604\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@1: 0.373592\u001b[0m\n",
      "\u001b[34mI0707 20:55:49.526791 140454606952256 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@1: 0.373592\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@10: 0.718601\u001b[0m\n",
      "\u001b[34mI0707 20:55:49.527712 140454606952256 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@10: 0.718601\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@100: 0.718814\u001b[0m\n",
      "\u001b[34mI0707 20:55:49.528613 140454606952256 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@100: 0.718814\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@100 (small): -1.000000\u001b[0m\n",
      "\u001b[34mI0707 20:55:49.529428 140454606952256 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@100 (small): -1.000000\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@100 (medium): 0.656364\u001b[0m\n",
      "\u001b[34mI0707 20:55:49.530348 140454606952256 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@100 (medium): 0.656364\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@100 (large): 0.723543\u001b[0m\n",
      "\u001b[34mI0707 20:55:49.813019 140454606952256 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@100 (large): 0.723543\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ Loss/localization_loss: 0.003235\u001b[0m\n",
      "\u001b[34mI0707 20:55:49.814350 140454606952256 model_lib_v2.py:1018] #011+ Loss/localization_loss: 0.003235\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ Loss/classification_loss: 0.535271\u001b[0m\n",
      "\u001b[34mI0707 20:55:49.815225 140454606952256 model_lib_v2.py:1018] #011+ Loss/classification_loss: 0.535271\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ Loss/regularization_loss: 0.029677\u001b[0m\n",
      "\u001b[34mI0707 20:55:49.815997 140454606952256 model_lib_v2.py:1018] #011+ Loss/regularization_loss: 0.029677\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ Loss/total_loss: 0.568183\u001b[0m\n",
      "\u001b[34mI0707 20:55:49.816761 140454606952256 model_lib_v2.py:1018] #011+ Loss/total_loss: 0.568183\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize training metrics with Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Due to this issue: https://github.com/ipython/ipykernel/issues/395#issuecomment-479787997\n",
    "#If you're using a custom conda env, there is a change that the tensorboard executable isn't in the Python path.\n",
    "#uncomment the following lines\n",
    "\n",
    "#bin_env_path = \"/home/ec2-user/anaconda3/envs/myenv/bin/\"\n",
    "#os.environ[\"PATH\"] += os.pathsep + bin_env_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_artifacts_path = estimator.latest_job_tensorboard_artifacts_path()\n",
    "job_artifacts_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize training outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Careful notebook would be stuck until you stop tensorboard, you can also launch this from a terminal\n",
    "tensorboard_s3_output_path = f'{job_artifacts_path}/train'\n",
    "!F_CPP_MIN_LOG_LEVEL=3 AWS_REGION=eu-west-1 tensorboard --logdir=$tensorboard_s3_output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize evaluation outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Careful notebook would be stuck until you stop tensorboard, you can also launch this from a terminal\n",
    "tensorboard_s3_output_path = f'{job_artifacts_path}/eval'\n",
    "!F_CPP_MIN_LOG_LEVEL=3 AWS_REGION=eu-west-1 tensorboard --logdir=$tensorboard_s3_output_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p38",
   "language": "python",
   "name": "conda_tensorflow2_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
